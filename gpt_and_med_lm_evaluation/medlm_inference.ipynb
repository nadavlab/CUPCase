{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVyv1Kt0E5HS"
      },
      "source": [
        "### Setup, Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0gx9wnUSL2h",
        "outputId": "16ced63d-df7e-47c1-fb0e-4e63b3f9e128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#!pip install google-cloud-aiplatform\n",
        "\n",
        "# The following restarts the runtime.\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "# Note that this will result in a pop-up telling you that the session has\n",
        "# crashed for an unknown reason. This can be safely ignored and you can continue\n",
        "# with the following cells after getting this message.\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhxina6EBTQK",
        "outputId": "5e854e59-a30e-4f39-cd4a-7e3c9018148a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXIK3B-MjDeR"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_gb82L7djtL6"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install bert_score\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-B5Am8xSMkM",
        "outputId": "8ce1c437-a41b-4f55-9a3c-557d72733928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response from Model:  Ringworm is a common fungal infection of the skin. It can affect people of all ages, and it is spread by contact with an infected person or animal. The fungus that causes ringworm can live on the skin, hair, and nails. Ringworm is most commonly found on the scalp, feet, and groin area. In most cases, ringworm is not a serious infection and can be treated with over-the-counter antifungal medications. However, in some cases, ringworm can cause severe itching and discomfort, and it may require treatment with prescription medications. If you are experiencing symptoms of ringworm, it is important to see a doctor for diagnosis and treatment.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth as google_auth\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "google_auth.authenticate_user()\n",
        "\n",
        "# TODO: Replace with project ID from Cloud Console\n",
        "# (https://support.google.com/googleapi/answer/7014113)\n",
        "PROJECT_ID = 'PROJECT_ID'\n",
        "\n",
        "# MedLM models are only available in us-central1.\n",
        "vertexai.init(project=PROJECT_ID, location='us-central1')\n",
        "\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"temperature\": 0.0,\n",
        "    \"top_k\": 40,\n",
        "    \"top_p\": 0.80,\n",
        "}\n",
        "\n",
        "model_instance = TextGenerationModel.from_pretrained(\"medlm-large\")\n",
        "response = model_instance.predict(\n",
        "    \"Question: What causes you to get ringworm?\",\n",
        "    **parameters\n",
        ")\n",
        "\n",
        "print(f\"Response from Model: {response.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpazzBoOjC5R"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import bert_score\n",
        "import os\n",
        "import random\n",
        "import openai\n",
        "\n",
        "google_auth.authenticate_user()\n",
        "PROJECT_ID = 'PROJECT_ID'\n",
        "vertexai.init(project=PROJECT_ID, location='us-central1')\n",
        "\n",
        "# Set up OpenAI API key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "ds = load_dataset('arrow', data_files={'test': '/content/drive/My Drive/data-00000-of-00001.arrow'})['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGTFrmiWCpHC"
      },
      "source": [
        "### CUPCase Eval MedLM-Large\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9n_XCTtFFgE"
      },
      "source": [
        "#### Free Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o3qGaC4Csuw"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.0,\n",
        "}\n",
        "\n",
        "model_instance = TextGenerationModel.from_pretrained(\"medlm-large\")\n",
        "\n",
        "results = []\n",
        "\n",
        "shuffled_ds = ds.shuffle(seed=42)\n",
        "\n",
        "batch_size = 250\n",
        "num_batches = 4\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_ds = shuffled_ds.select(range(start_idx, end_idx))\n",
        "\n",
        "    for idx, example in enumerate(batch_ds):\n",
        "        case_presentation = example['clean_case_presentation']\n",
        "        true_diagnosis = example['correct_diagnosis']\n",
        "        prompt = (f\"Predict the diagnosis of this case presentation of a patient. Return the final diagnosis in one concise sentence \"\n",
        "                  f\"without any further elaboration.\\nFor example: <diagnosis name here>\\nCase presentation: {case_presentation}\\nDiagnosis:\")\n",
        "\n",
        "        response = model_instance.predict(prompt, **parameters)\n",
        "        generated_diagnosis = response.text.strip()\n",
        "        results.append({\n",
        "            'Case presentation': case_presentation,\n",
        "            'True diagnosis': true_diagnosis,\n",
        "            'Generated diagnosis': generated_diagnosis\n",
        "        })\n",
        "\n",
        "        # Sleep every 50 samples\n",
        "        if (idx + 1) % 50 == 0:\n",
        "            time.sleep(3)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "model_type = \"microsoft/deberta-xlarge-mnli\"\n",
        "predictions = results_df['Generated diagnosis'].tolist()\n",
        "references = results_df['True diagnosis'].tolist()\n",
        "\n",
        "P, R, F1 = bert_score.score(predictions, references, lang=\"en\", model_type=model_type)\n",
        "\n",
        "results_df['BERTScore F1'] = F1.tolist()\n",
        "\n",
        "results_df.to_csv('free_text_medlm_large.csv', index=False)\n",
        "\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cVfiPF_FKES"
      },
      "source": [
        "#### Multi Choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxV3GgcjYeFS"
      },
      "outputs": [],
      "source": [
        "\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.0,\n",
        "}\n",
        "\n",
        "model_instance = TextGenerationModel.from_pretrained(\"medlm-large\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# Shuffle the dataset\n",
        "shuffled_ds = ds.shuffle(seed=42)\n",
        "\n",
        "batch_size = 250\n",
        "num_batches = 4\n",
        "\n",
        "# Process each batch\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_ds = shuffled_ds.select(range(start_idx, end_idx))\n",
        "\n",
        "    # Track the number of processed samples\n",
        "    for idx, example in tqdm(enumerate(batch_ds), total=len(batch_ds), desc=\"Processing batch\"):\n",
        "        case_presentation = example['clean_case_presentation']\n",
        "        true_diagnosis = example['correct_diagnosis']\n",
        "        distractor2 = example['distractor2']\n",
        "        distractor3 = example['distractor3']\n",
        "        distractor4 = example['distractor4']\n",
        "\n",
        "        options = [true_diagnosis, distractor2, distractor3, distractor4]\n",
        "        random.shuffle(options)\n",
        "        options_text = \"\\n\".join([f\"{i+1}. {option}\" for i, option in enumerate(options)])\n",
        "        prompt = (f\"Predict the diagnosis of this case presentation of a patient. Return only the correct index from the following list, for example: 3\\n\"\n",
        "                  f\"{options_text}\\nCase presentation: {case_presentation}\")\n",
        "\n",
        "        # Retry logic\n",
        "        while True:\n",
        "            try:\n",
        "                response = model_instance.predict(prompt, **parameters)\n",
        "                generated_diagnosis = response.text.strip()\n",
        "\n",
        "                try:\n",
        "                    predicted_index = int(generated_diagnosis[0]) - 1\n",
        "                except Exception as e:\n",
        "                    predicted_index = -1\n",
        "                    print(e)\n",
        "\n",
        "                print(predicted_index)\n",
        "                break  # Exit the retry loop if successful\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred. Retrying in 5 seconds...{e}\")\n",
        "                time.sleep(5)  # Sleep for 5 seconds and retry\n",
        "\n",
        "        try:\n",
        "            results.append({\n",
        "                'Case presentation': case_presentation,\n",
        "                'True diagnosis': true_diagnosis,\n",
        "                'Generated diagnosis': generated_diagnosis,\n",
        "                'Correct index': options.index(true_diagnosis),\n",
        "                'Predicted index': predicted_index,\n",
        "                'Correct': options.index(true_diagnosis) == predicted_index\n",
        "            })\n",
        "        except Exception:\n",
        "            print(\"An error occurred while appending results.\")\n",
        "\n",
        "        # Sleep every 50 samples\n",
        "        if (idx + 1) % 50 == 0:\n",
        "            results_df = pd.DataFrame(results)\n",
        "            results_df.to_csv(f'checkpoint_{idx}.csv')\n",
        "            time.sleep(3)\n",
        "\n",
        "# Save results to a DataFrame and CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('qa_medlm_large.csv', index=False)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(results_df['Correct'], [True]*len(results_df))\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nh9BqNgTFYEZ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}